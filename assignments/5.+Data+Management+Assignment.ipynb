{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e94619e6959de309a9d372686de600d6",
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Management and Pre-Processing of Data - Due 29th July (23:59)\n",
    "\n",
    "In this assessment you will go through the process of obtaining data, cleaning it, and then querying it from a database.  We are using data about food hygiene from UK open data.  The data stored is a copy of the official data.\n",
    "\n",
    "To provide a solution for each task, you might like to do the practice exercises: \"HTML and Page Scraping\", and \"Using MongoDB to Retrieve Information\" first.\n",
    "\n",
    "You may validate your answers by clicking \"Validate\" on the \"Assignments\" tab for this exercise.  These will be done automatically, using the tests in this notebook.  The final submission will be both machine checked and human marked.\n",
    "\n",
    "## Question 0: Setup [1 mark]\n",
    "\n",
    "Run the following cell to import the core dependencies required for this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# You don't need to write anything here\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.robotparser import RobotFileParser\n",
    "from nose.tools import assert_equal, assert_raises\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0b1cd74161a6c74e59860ac548f6cd75",
     "grade": true,
     "grade_id": "setup-tests",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported libraries and functions\n"
     ]
    }
   ],
   "source": [
    "# Check that the required libraries and functions have been imported\n",
    "# You don't need to write anything here\n",
    "\n",
    "try:\n",
    "    imports = [requests, BeautifulSoup, RobotFileParser, assert_equal, assert_raises, json, MongoClient]\n",
    "except NameError as e:\n",
    "    print(e)\n",
    "    raise AssertionError('You appear to be missing one of the required libraries or functions')\n",
    "assert True\n",
    "print('Successfully imported libraries and functions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Web APIs and Page Scraping\n",
    "\n",
    "\n",
    "\n",
    "### Question 1(a) [2 marks]\n",
    "\n",
    "Write a function `get_establishment_by_id` which accepts a parameter `id`, and returns the name of that business as a string.  It should obtain the data from the [food hygeine ratings API](http://ratings.food.gov.uk/open-data/en-GB), and use version 2 of the API.\n",
    "- You may **assume that the ID exists**\n",
    "- You should use the **`Establishments`** endpoint  \n",
    "\n",
    "To complete this question you may wish to look at the information found [here](http://docs.python-requests.org/en/master/user/quickstart/).   \n",
    "\n",
    "**N.B.** The version of requests installed on the server is relatively recent.  In a previous update, there was a breaking change which meant that only strings or byte-like objects could be passed as headers.  As such, if you wish to pass an integer, you will have to do it as e.g., `{'header_name': '4321'}`.  \n",
    "\n",
    "*Hint: Week 3, Guided Exercise 2, Scraping With Requests and Beautiful Soup*\n",
    "\n",
    "*Read: the information given regarding api version in [link page](http://api.ratings.food.gov.uk/help). Remebering that you don't need to include '/Help/Api/GET-' in the URL*\n",
    "\n",
    "*Read: the information in the requests ['Quickstart Guide'](http://docs.python-requests.org/en/master/user/quickstart/) with regard ['Custom Headers'](http://docs.python-requests.org/en/master/user/quickstart/#custom-headers) and ['JSON Response Content'](http://docs.python-requests.org/en/master/user/quickstart/#json-response-content)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "The food hygiene rating data published at www.food.gov.uk/ratings are available via an application programming interface (API) in XML and JSON formats. Therefore format must use a .json() decoder<br>\n",
    "Version 2 of the food hygeine ratings API must be included in headers<br>\n",
    "Please note: If a version is not supplied in the header, calls to FHRS API endpoints will not return data.<br>\n",
    "'BusinessName' column from the Establishments dataset for the specified id number. See the requests body format on URL.<br>\n",
    "Return the name of business as a string<br>\n",
    "### Hint\n",
    "%d is the placeholder for id (d for data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://api.ratings.food.gov.uk/Help/Api/GET-Establishments-id'\n",
    "headers = {'x-api-version': '2'}\n",
    "r = requests.get(url, headers=headers)\n",
    "r.status_code #success 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(r.headers) #headers the servers sent back\n",
    "#print(r.text) #full text\n",
    "#print(r.encoding) #utf-8\n",
    "#print(r.request.headers) #headers I sent to the server, includes the v2 header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "dd14997686784bf255fabcb75713feb9",
     "grade": false,
     "grade_id": "api-json",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Star Karahi'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_establishment_by_id(id):\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "    '''num -> string\n",
    "    Using the establishment id number, return the name of that business\n",
    "    '''\n",
    "    \n",
    "    url = 'http://api.ratings.food.gov.uk/Establishments/%d' %id\n",
    "    headers = {'x-api-version': '2'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    \n",
    "    return r.json()['BusinessName']\n",
    "\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "get_establishment_by_id(511819)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5fa6acdf237ca5e3ff9dac7f8d451575",
     "grade": true,
     "grade_id": "api-json-tests",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests successfully passed\n"
     ]
    }
   ],
   "source": [
    "assert_equal(get_establishment_by_id(492474), '360 Beach and Watersports Centre')\n",
    "assert_equal(get_establishment_by_id(511819), 'Star Karahi')\n",
    "assert_equal(get_establishment_by_id(692630), 'Baldiesburn Bed & Breakfast')\n",
    "print('All tests successfully passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1(b) [2 marks]\n",
    "\n",
    "Data stored at **http://138.68.148.20/**, in HTML format will be used for this question.  Use the Python `requests` library for any requests to the server:\n",
    "\n",
    "**Write a function** `check_robots`, which accepts a **parameter** `url` which tells you whether the server at **http://138.68.148.20/** will permit you to scrape that page.  \n",
    "\n",
    "*Hint: Week 3, Guided Exercise 2, Robots.txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "99bf9b54ddabe6633a719c802e6d38fd",
     "grade": false,
     "grade_id": "page-scraping-robots",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def check_robots(url):\n",
    "    \"\"\"\n",
    "    Use the RobotFileParser to check if a page on the server can be visited\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    rp = RobotFileParser()\n",
    "    rp.set_url('http://138.68.148.20/robots.txt')\n",
    "    rp.read()\n",
    "    return rp.can_fetch('*', url) \n",
    "    \n",
    "    #raise NotImplementedError()\n",
    "    \n",
    "#check_robots('http://138.68.148.20/')   \n",
    "#check_robots('http://138.68.148.20/index.html')\n",
    "#not check_robots('http://138.68.148.20/data/scotland/glasgow_city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "eddb09bdae9daf58c0e0b533ad809820",
     "grade": true,
     "grade_id": "page-scraping-robots-tests",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed all the tests\n"
     ]
    }
   ],
   "source": [
    "# Testing whether your code works correctly.  \n",
    "# You don't need to write anything here\n",
    "\n",
    "# Confirm an allowed page returns True\n",
    "assert check_robots('http://138.68.148.20/index.html')\n",
    "# Confirm a disallowed page returns False\n",
    "assert not check_robots('http://138.68.148.20/data/scotland/glasgow_city')\n",
    "print('Passed all the tests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1(c) [3 marks]\n",
    "\n",
    "Write a function which takes a URL as a **parameter**, and reads the **XML** on the page it goes to.  The function should **return** a `dict` with the amount of records in `EstablishmentCollection`, and the name of the first business.  \n",
    "**HINT (READ THIS)**: You can use `BeautifulSoup` for parsing XML as well as HTML.  The function should behave as follows:\n",
    "- The function should use the Python **`requests`** library.\n",
    "- **If** the page is banned by robots.txt, then it should not be visited, and should return **`None`**\n",
    "- **If** the page does not return a **200 status code** in response, then it should not attempt to parse the result, and return **`None`**\n",
    "- If the page is an **XML** file, it should return a dict in the following format: `{'first_business': 'business name', 'amount_of_records': 1234}`\n",
    "\n",
    "N.B. The order of a Python `dict` is not guaranteed, so we will not take into account which key appears first.  \n",
    "\n",
    "*Hint: Week 3, Guided Exercise 2, Parsing HTML - Scraping with Requests and Beautiful Soup*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "1st Choice Pizza/Fish & Chips\n",
      "{'first_business': '1st Choice Pizza/Fish & Chips', 'amount_of_records': 731}\n"
     ]
    }
   ],
   "source": [
    "r = requests.get('http://138.68.148.20/data/west_midlands/cannock_chase')\n",
    "\n",
    "doc = r.content #create the XML file\n",
    "print(r.status_code)\n",
    "soup = BeautifulSoup(doc, 'xml')\n",
    "#doc\n",
    "var = soup.find('BusinessName').text\n",
    "print(var)\n",
    "var2 = len(soup.find_all('BusinessName'))\n",
    "var2\n",
    "print({'first_business': var, 'amount_of_records': var2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d9194441a2f59471ee9548d9c580096e",
     "grade": false,
     "grade_id": "get-urls",
     "locked": false,
     "points": 0,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def parse_xml(url):\n",
    "    \"\"\"\n",
    "    string -> dict\n",
    "    This function should parse the XML file, for example http://138.68.148.20/west_midlands/cannock_chase\n",
    "    NOTE: Unlike for HTML, you need to use 'xml' as the second parameter for BeautifulSoup\n",
    "    You may use any of Python's core libraries, or other libraries installed if you wish rather than BeautifulSoup\n",
    "    \n",
    "    >>> parse_xml('http://138.68.148.20/data/west_midlands/cannock_chase')\n",
    "        {'amount_of_records': 731, 'first_business': '1st Choice Pizza/Fish & Chips'}\n",
    "    >>> parse_xml('http://138.68.148.20/data/wales/swansea')                     \n",
    "        {'amount_of_records': 1700, 'first_business': '360 Beach and Watersports Centre'})\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    #use robots.txt to answer: can I scrap the page?\n",
    "    if check_robots(url):#if it's True continue and parse\n",
    "        r = requests.get(url)\n",
    "        \n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        \n",
    "        var = r.content #create the xml file\n",
    "        soup = BeautifulSoup(var, 'xml')\n",
    "        #find the name of the first business in the collection\n",
    "        var2 = soup.find('BusinessName').text\n",
    "        #find the amount of records in establishment collection\n",
    "        var3 = len(soup.find_all('BusinessName'))\n",
    "        \n",
    "        return {'first_business': var2, 'amount_of_records': var3}\n",
    "        \n",
    "    return None\n",
    "    \n",
    "    #raise NotImplementedError()\n",
    "#parse_xml('http://138.68.148.20/data/west_midlands/cannock_chase')\n",
    "parse_xml('http://138.68.148.20/data/scotland/clackmannanshire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "79a7a942d07a44d9f7a3fda1e8b5884b",
     "grade": true,
     "grade_id": "get-urls-test",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test successfully passed\n"
     ]
    }
   ],
   "source": [
    "# You don't need to write anything here\n",
    "# Confirm that the function calls the check_robots function\n",
    "tmp_check_robots = check_robots\n",
    "del check_robots\n",
    "\n",
    "try:\n",
    "    parse_xml('http://138.68.148.20/data/west_midlands/cannock_chase')\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"get_urls does not call check_robots\")\n",
    "finally:\n",
    "    check_robots = tmp_check_robots\n",
    "\n",
    "# TEST NOT VISITING PAGES PROHIBITED BY ROBOTS\n",
    "# THIS SHOULD NOT CALL requests.get\n",
    "\n",
    "tmp_requests = requests\n",
    "del requests\n",
    "\n",
    "try:\n",
    "    parse_xml('http://138.68.148.20/data/scotland/glasgow_city')\n",
    "    parse_xml('http://138.68.148.20/data/scotland/clackmannanshire')\n",
    "except NameError:\n",
    "    raise AssertionError(\"The function should not be using requests on this URL\")\n",
    "finally:\n",
    "    requests = tmp_requests\n",
    "# TEST OUTPUT RESPONSE\n",
    "assert_equal(parse_xml('http://138.68.148.20/data/west_midlands/cannock_chase'), \n",
    "             {'amount_of_records': 731, 'first_business': '1st Choice Pizza/Fish & Chips'})\n",
    "assert_equal(parse_xml('http://138.68.148.20/data/wales/swansea'), \n",
    "                       {'amount_of_records': 1700, 'first_business': '360 Beach and Watersports Centre'})\n",
    "# TEST HANDLING 404\n",
    "assert_equal(parse_xml('http://138.68.148.20/data/calderdale'), None)\n",
    "\n",
    "print('All test successfully passed')\n",
    "                       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Retrieving Data from MongoDB\n",
    "\n",
    "We will assume that you have successfully cleaned the data, and have stored it in the MongoDB database.  Using the following PyMongo configuration, answer the following questions about the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are the credentials to connect to the database\n",
    "# You don't need to write anything here, but you need to run this cell\n",
    "\n",
    "client = MongoClient('mongodb://cpduser:M13pV5woDW@mongodb/health_data')\n",
    "db = client.health_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2(a) [1 mark]\n",
    "\n",
    "Write a **function** `get_count`, which takes a PyMongo collection object as a parameter and **returns** the amount of businesses in the collection.  \n",
    "\n",
    "*Hint: Week 3, Guided Exercise 4, Using MongoDB to Retrieve Information*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1952"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.collection_names() #outputs list of collection names\n",
    "db.aberdeenshire.count() #db.collection.count() method does not perform the find() operation \n",
    "#but instead counts and returns the number of results that match a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "d9d11ead5846b5fb262bbe278908cf7a",
     "grade": false,
     "grade_id": "q4-count",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_count(collection):\n",
    "    \"\"\"\n",
    "    Return an integer which gives the amount of unique businesses in the given collection\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return collection.count()\n",
    "    #raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "221256faad282cc5acc9fa603b3e91d4",
     "grade": true,
     "grade_id": "q4-count-tests",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed all the tests\n"
     ]
    }
   ],
   "source": [
    "# You don't need to write anything here\n",
    "assert_equal(get_count(db.uk), 511819)\n",
    "assert_equal(get_count(db.swansea), 1700)\n",
    "assert_equal(get_count(db.westminster), 4315)\n",
    "assert_equal(get_count(db.newcastle_upon_tyne), 2308)\n",
    "print('Passed all the tests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2(b) [3 marks]\n",
    "\n",
    "Write a **function** `get_rating_value_percentage` which **returns** the **percentage** of businesses which were awarded an overall `RatingValue` of 5.  The function should accept a parameter `collection` of type `Collection`, for which it should return the percentage as a **float** between 0 and 1.  \n",
    "\n",
    "*Hint: Week 3, Guided Exercise 4, Cursors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6688235294117647"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = get_count(db.swansea.find({'RatingValue': {'$gte': 5}}))\n",
    "var2 = get_count(db.swansea)\n",
    "var/var2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2feec2f3543437b732469673f70e265f",
     "grade": false,
     "grade_id": "q4-rating-value-percentage",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_rating_value_percentage(collection):\n",
    "    \"\"\"\n",
    "    Return a float between 0 and 1 of the amount with a RatingValue of 5\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    star_5 = get_count(collection.find({'RatingValue':{'$gte': 5}}))\n",
    "    all_bus = get_count(collection)\n",
    "    return star_5/all_bus\n",
    "    \n",
    "    #raise NotImplementedError()\n",
    "    \n",
    "#get_rating_value_percentage(db.uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4700f748b3d7da10aa9332fbd717dcbe",
     "grade": true,
     "grade_id": "q4b-rating-value-percentage-tests",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed all the tests\n"
     ]
    }
   ],
   "source": [
    "# You don't need to write anything here\n",
    "assert_equal(get_rating_value_percentage(db.uk), 0.5287240215779406)\n",
    "assert_equal(get_rating_value_percentage(db.swansea), 0.6688235294117647)\n",
    "assert_equal(get_rating_value_percentage(db.westminster), 0.4600231749710313)\n",
    "assert_equal(get_rating_value_percentage(db.newcastle_upon_tyne), 0.5966204506065858)\n",
    "print('Passed all the tests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2(c) [3 marks]\n",
    "\n",
    "Write a **function** `get_no_geocode` which will find establishments with region Scotland which do not have a `Geocode` recorded.  The parameter `establishment_type` is a string, which will indicate the type of establishment to search for.  All queries should be run on the `uk` collection.\n",
    "\n",
    "The function should **return** a PyMongo **`Cursor`** object, with only the following fields:\n",
    "- `BusinessName`, `BusinessType`, and `LocalAuthorityName`.  \n",
    "- `_id` should not be included  \n",
    "\n",
    "*Hint: Week 3, Guided Exercise 4, Returning Part of a Document*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BusinessName': 'AMT Coffee',\n",
       " 'BusinessType': 'Takeaway/sandwich shop',\n",
       " 'LocalAuthorityName': 'Edinburgh (City of)'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.uk.count({'Region': 'scotland'})\n",
    "db.uk.find_one({'Region': 'scotland'})\n",
    "db.uk.find_one({'Region': 'scotland', 'BusinessType': 'Takeaway/sandwich shop', 'Geocode': None}, \n",
    "               {'BusinessName': 1, 'BusinessType': 1, 'LocalAuthorityName': 1, '_id': 0})                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "dcc25b22b0f3e5d8a85087437da6b7e4",
     "grade": false,
     "grade_id": "no-geocode-find",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_no_geocode(establishment_type):\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    var = db.uk.find({'Region': 'scotland', 'BusinessType': establishment_type, 'Geocode': None},\n",
    "                    {'BusinessName': 1, 'BusinessType': 1, 'LocalAuthorityName': 1, '_id': 0})\n",
    "    \n",
    "    return var\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "#len(list(get_no_geocode('Takeaway/sandwich shop')))\n",
    "#len(list(get_no_geocode('Retailers - other')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "48f965b1b16f7dac00a95e1f13f667f8",
     "grade": true,
     "grade_id": "no-geocode-test",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed all the tests\n"
     ]
    }
   ],
   "source": [
    "# You don't need to write anything here\n",
    "\n",
    "cursor = get_no_geocode('Restaurant/Cafe/Canteen' )\n",
    "for cur in cursor:\n",
    "\n",
    "    assert '_id' not in cur\n",
    "    assert 'BusinessType' in cur\n",
    "    assert_equal(cur['BusinessType'], 'Restaurant/Cafe/Canteen')\n",
    "    assert 'BusinessName' in cur    \n",
    "    assert 'LocalAuthorityName' in cur\n",
    "\n",
    "assert_equal(len(list(get_no_geocode('Takeaway/sandwich shop'))), 405)\n",
    "assert_equal(len(list(get_no_geocode('Retailers - other'))), 1079)\n",
    "print('Passed all the tests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "## Question 2(d) [5 marks]\n",
    "\n",
    "What was the earliest and latest dates that an inspection was carried out? Write a **function** which returns a dict in the form `{'earliest_date': 'YYYY-MM-DD', 'latest_date': 'YYYY-MM-DD'}`.  \n",
    "\n",
    "*Hint: Week 3, Guided Exercise 4, MongoDB Aggregation Framework*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'earliest_date': '1989-01-01', 'latest_date': '2016-09-15'}\n"
     ]
    }
   ],
   "source": [
    "var = db.uk.aggregate([{'$group':{'_id': None, 'earliest':{'$min': '$RatingDate'}, 'latest':{'$max': '$RatingDate'}}}])\n",
    "for date in var:\n",
    "# dataset format YYYY, M, D, ?, ?\n",
    "    earliest = date['earliest']\n",
    "    latest = date['latest']\n",
    "    date_format = '%Y-%m-%d'\n",
    "    e = datetime.strftime(earliest, date_format)\n",
    "    l = datetime.strftime(latest, date_format)\n",
    "    print({'earliest_date': e, 'latest_date': l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "69c6468b4ba05cf95e629ab69a13c20b",
     "grade": false,
     "grade_id": "q4c-earliest-latest",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'earliest_date': '1989-01-01', 'latest_date': '2016-09-15'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "def get_earliest_and_latest_dates(collection):\n",
    "    # YOUR CODE HERE\n",
    "    # pass a list using aggregate \n",
    "    var = collection.aggregate([{'$group':{'_id': None,'earliest':{'$min': '$RatingDate'}, 'latest':{'$max': '$RatingDate'}}}\n",
    "                                # now that I have the datsets, I need to iterate through the var \n",
    "    ])\n",
    "    for date in var:\n",
    "        earliest = date['earliest']\n",
    "        latest = date['latest']\n",
    "        date_format = '%Y-%m-%d' #convert dates into YYYY-MM-DD\n",
    "        earliest = datetime.strftime(earliest, date_format)\n",
    "        latest = datetime.strftime(latest, date_format)\n",
    "        #finally return a dictionary with 'earliest_date' and 'latest_date'\n",
    "        return {'earliest_date': earliest, 'latest_date': latest}\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "get_earliest_and_latest_dates(db.uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "689ef62151f38304cfc0acfff8676d81",
     "grade": true,
     "grade_id": "q4c-earliest-latest-test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed all the tests\n"
     ]
    }
   ],
   "source": [
    "# You don't need to write anything here\n",
    "assert_equal(get_earliest_and_latest_dates(db.uk),{'earliest_date': '1989-01-01', 'latest_date': '2016-09-15'})\n",
    "assert_equal(get_earliest_and_latest_dates(db.swansea),{'earliest_date': '2010-10-06', 'latest_date': '2016-08-16'})\n",
    "assert_equal(get_earliest_and_latest_dates(db.westminster), \n",
    "                {'earliest_date': '1999-01-27', 'latest_date': '2016-09-13'})\n",
    "assert_equal(get_earliest_and_latest_dates(db.newcastle_upon_tyne), \n",
    "                {'earliest_date': '2005-07-08', 'latest_date': '2016-09-06'})\n",
    "print('Passed all the tests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 Exploring and fixing data [5 marks]\n",
    "\n",
    "During this week Huw has talked about issues which may arise when integrating data. For this task, consider the data described in this notebook, and any other source you wish.\n",
    "- Provide two concise examples of possible issues, and their mitigation in relation to these data\n",
    "- Each example should be approximately one paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dd189ef41dff533c59328c760b737f31",
     "grade": true,
     "grade_id": "descriptive",
     "locked": false,
     "points": 5,
     "solution": true
    }
   },
   "source": [
    "The data described in this notebook is from food.gov.uk describing  food hygiene ratings. The data is fairly large with around 500,000 records. Within each record in the collection are data attributes with numerical, text, and boolean values. \n",
    "### Example one\n",
    "We may want to discover the correlation between a restaurant and stomach illness/food poisoning by integrating the food hygiene rating dataset with GP records. A possible problem that could arise is different measurement values when it comes to the Geocode attribute. The cause of this could be different instrument settings and readings at data collection and entry. The coordinate value may be in a different format, for example the food hygiene is in Decimal Degrees, whereas GP locations may be in Degrees, Minutes, Seconds. One of the datasets would require converting/transformation for data integration consistency. It is also worth noting that different datasets for location based data may use a different datums (for example WGS84 and ED50) meaning the coordinate values would need transformed to the same reference system.\n",
    "\n",
    "\n",
    "### Example two\n",
    "If I was integrating the food hygiene rating with Trip Adviser reviews, I could encounter the problem of overlapping data with a naming conflict. Food hygiene may refer to the name of the restaurant as 'BusinessName', and Trip Adviser may use 'RestaurantName'. This is an example of a synonym; different name, same object. To mitigate this problem an agreed term would be used within the dataset, i.e. 'RestaurantName', and the integrated dataset header/tag would reflect this. \n",
    "\n",
    "Overall I would use a data cleaning technique called entity resolution to keep additional, complimenting information between two integrating datasets and to remove any duplication."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
