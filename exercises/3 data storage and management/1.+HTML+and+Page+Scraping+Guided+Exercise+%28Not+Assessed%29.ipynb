{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML and Page Scraping Guided Exercise\n",
    "\n",
    "In this guided exercise, we are going to look at a few of the programming libraries you are going to need for the first assessment.  We are going to cover:\n",
    "\n",
    "- HTML\n",
    "- RobotParser\n",
    "- Python Requests and Beautiful Soup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML\n",
    "\n",
    "HTML is a markup language where content can be represented in a manner which Web browsers can understand.  It is distinct from the _style_ of the display, which is dealt with by Cascading Style Sheets (CSS).  It is composed of a series of _tags_ and attributes.  The following Python **variable** ('html'), represents an HTML document, which is structured as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure that you run this code as this will be interrogated later in this exercise\n",
    "# Reminder - 'html' is variable\n",
    "html = \"\"\"\n",
    "        <html>\n",
    "            <head>\n",
    "                <!--Metadata about the document goes within the <head> tag, including Stylesheet declarations, title and \n",
    "                encoding-->\n",
    "                <title>Example HTML Structure</title>\n",
    "\n",
    "                <style type=\"text/css\">\n",
    "                    body{\n",
    "                        font-size:12pt;\n",
    "                    }\n",
    "                    table{\n",
    "                        border: solid 1px black;\n",
    "                    }\n",
    "                </style>\n",
    "\n",
    "                <link href=\"/style.css\" rel=\"stylesheet\">\n",
    "\n",
    "                <meta charset=\"utf-8\">\n",
    "                <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "            </head>\n",
    "\n",
    "            <body>\n",
    "                <div id=\"main\" class=\"classy\">\n",
    "                    <h1>The Main Content of the Document</h1>\n",
    "\n",
    "                    <p>This is some content inside a &lt;p&gt; tag.  It is normal writing.  It can contain other tags\n",
    "                    within it.  For example, to emphasise a word I would use <em>the &lt;em&gt; tag</em>, or to move\n",
    "                    onto a new ine I could use the &lt;br /&gt; tag.\n",
    "                    </p>\n",
    "\n",
    "                    <table>\n",
    "                        <tr>\n",
    "                            <th>Table heading cell<br></th><th>Another heading</th>\n",
    "                        </tr>\n",
    "                        <tr>\n",
    "                            <td>Normal table cell and <br></td>\n",
    "                            <td>This cell has a link going <a href=\"#\">Somewhere</a></td>\n",
    "                        </tr>\n",
    "                    </table>\n",
    "\n",
    "                </div>\n",
    "\n",
    "                <div id=\"another_div\" class=\"classy\">\n",
    "                    <ul>\n",
    "                        <li>An unordered (numbered) list item</li>\n",
    "                        <li>And another unordered list item</li>                    \n",
    "                    </ul>\n",
    "                    <ol>\n",
    "                        <li>This list item is ordered</li>\n",
    "                        <li>So is this one</li>\n",
    "                    </ol>\n",
    "                    <table>\n",
    "                        <tr>\n",
    "                            <th>Table 2<br></th><th>A second heading</th>\n",
    "                        </tr>\n",
    "                        <tr>\n",
    "                            <td>Cool content and <br></td>\n",
    "                            <td>This cell has a link going <a href=\"#\">SomewhereElse</a></td>\n",
    "                        </tr>\n",
    "                    </table>                \n",
    "                </div>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot going on in that HTML snippet, so let's break it down:\n",
    "## Tags\n",
    "\n",
    "Each tag of the form &lt;tagname&gt; represents a HTML element.  Usually, the tags are closed with a tag of the same name but including `/` after the opening bracket, for example &lt;/tagname&gt;, like `<body></body>`.  These tags can have other tags and content inside them.  Notice that `<body>` has a `<div>` tag inside it.  `<div>` doesn't do much, but merely acts as a logical area of the document which can be referred to later (e.g., for styling).\n",
    "\n",
    "For the most part, the tags represent some sort of content.  A `<h1>` tag would represent a heading, with `<h2>` down to `<h6>` being subheadings.  You can see a `<p>` tag - which stands for paragraph, which opens and closes such that everything inside it represents a single paragraph.\n",
    "\n",
    "There is a `<table>` tag as well, which represents a table.  Inside this tag, you will notice that there are many other tags inside that representing rows and cells.\n",
    "\n",
    "Although most tags follow the format of opening and closing tags, some are different - referred to as \"self closing\" tags.  These don't need to have any content inside them, but represent some part of the document.  The most common example is the breakline `<br />` tag, which moves content on to the next row.  \n",
    "\n",
    "There are also special tags, which are used for different purposes:\n",
    "- Comments, written as `<!-- A useful comment here -->` do not count as content, but rather are there to document the code.\n",
    "- The `<style>` tag means that anything inside that will be a stylesheet, which will almost always be in CSS.  This allows separation of the content (the rest of the HTML document) and the styling (this tag).  It is also possible to link to CSS in an external file.  We don't cover CSS in this course, but check out [this CSS tutorial](https://www.w3schools.com/css/default.asp) if you are interested.\n",
    "- The `<script>` tag (not included in this document) includes some form of scripting done by the browser. This will almost always be Javascript.\n",
    "\n",
    "\n",
    "\n",
    "### Test Yourself\n",
    "In the next cell, try and write a paragraph tag with some text inside it including at least one breakline.\n",
    "\n",
    " N.B. make sure that 'Markdown' format has been selected and to double click the cell if you want to edit the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Hello this a test<br>\n",
    "Thank you for reading this, the answer is <em>42 </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes\n",
    "\n",
    "Several of the cells also have attributes, which is the quoted text within the opening tag.  There are three attributes which are important to know:\n",
    "- `href=\"\"` is used within an anchor or &lt;a&gt; tag and represents the hyperlink to another resource such as another page.  So `<a href=\"http://example.com\">Destination Link</a>` will have the text \"Destination Link\" which when clicked on it will go to http://example.com\n",
    "- `id` represents the ID of a element.  This should be unique within a page.  It is often used for styling, but can be very useful for pagescraping, because it can be used to identify an element of interest\n",
    "- `class` is similar to `id`, but it is used by more than one of the instances of a particular tag, but more specific than a general style.\n",
    "- There are also some `<meta>` tags, which simply provide metadata about the document itself.  These provide information about the document itself.  These usually have an attribute `name=\"\"` and `content=\"\"`.  Full details of the `<meta>` tags can be found at [w3schools](https://www.w3schools.com/tags/tag_meta.asp)\n",
    "\n",
    "### Test Yourself\n",
    "\n",
    "In the cell below, write an anchor tag which links to http://southamptondata.science with the text \"Data Science!\" inside it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "<a href=\"http://southamptondata.science/\"> Data Science! </a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping With Requests and Beautiful Soup\n",
    "\n",
    "Python has got its own libraries for dealing with HTTP, but at least historically, they required a lot of low level effort to get them to work properly.  The Python requests library abstracts a lot of that away, and makes it relatively easy to simply download a page.  The syntax is simple.  To get a page, all you need to do is say which request verb you want (usually `get`) and write it as follows:\n",
    "\n",
    "**N.B.** The version of Python Requests running on this server is 2.11.1, which was released in August 2016.  This makes a change to the function which processes the headers passed to any function.  Previously, it would allow any type, but the previous verion to this made a security improvement that any value has to be a string.  \n",
    "\n",
    "For example, you would put in **`headers = {'header-name': '2'}`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Cache-Control': 'private', 'Server': 'Microsoft-IIS/10.0', 'Vary': 'Accept-Encoding', 'Set-Cookie': 'ASP.NET_SessionId=4k4yfugq5w0bp04reje45tiv; path=/; HttpOnly, ii_Globalisation=Create=1; expires=Sun, 14-Jul-2019 21:02:13 GMT; path=/; HttpOnly', 'X-AspNet-Version': '4.0.30319', 'Content-Type': 'text/html; charset=utf-8', 'Content-Length': '13460', 'Content-Encoding': 'gzip', 'Date': 'Sat, 14 Jul 2018 21:02:12 GMT'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You don't need to write anything here\n",
    "import requests\n",
    "r = requests.get('http://southamptondata.science')\n",
    "print(r.status_code)\n",
    "\n",
    "r.headers\n",
    "\n",
    "# What does the returned code mean? 200 OK: The request has succeeded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces a `Response` object.  It has many different properties, but the important ones for our purposes are:\n",
    "- `r.text` The text of the body of the response, in this case the HTML of the Web page.\n",
    "- `r.status_code` An integer which represents the success of the request.  For example, `200` means sucess and `404` means page not found.  See the full list of status codes on [Wikipedia](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "\n",
    "It is not only HTML that the `requests` library can accept, but it can make any HTTP request.  Notably, there is a `.json()` function which will give the JSON associated with any request.  \n",
    "\n",
    "We can also add more detail to the request by adding further parameters to the request.  You can add a `params=` and `headers=` parameter, which allow you to edit the parameters and headers respectively.  Check out the [Quickstart](http://docs.python-requests.org/en/master/user/quickstart/) and [Advanced Usage](http://docs.python-requests.org/en/master/user/advanced/) for some examples of more of the things you can do.\n",
    "\n",
    "\n",
    "Write your own request to go to the [GitHub homepage](https://github.com). Manually check on whether you are allowed to visit according to the `robots.txt` file, generate the request, and then inspect the response that you get.  You can use the function `vars` to give details of any Python object, taking the variable as a parameter, or you can get individual fields from the response such as `status_code`, `content` or `headers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "r = requests.get('https://github.com/')\n",
    "print(r.status_code)\n",
    "#r.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An [HTTP header](https://en.wikipedia.org/wiki/List_of_HTTP_header_fields) is part of the HTTP protocol, which defines the way in which a particular HTTP session will work.  For example, a client could declare itself to be a certain type of browser by using the `User-Agent` header, and this was previously used by servers as a means of deciding how to serve particular content, which has a [long and complex history](http://webaim.org/blog/user-agent-string-history/).\n",
    "\n",
    "See how the Python requests library declares itself, and in the cell below try and change some of the headers in the request, using the `headers` parameter to the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accept-Encoding': 'gzip, deflate', 'Connection': 'keep-alive', 'User-Agent': 'python-requests/2.11.1', 'Accept': '*/*'}\n"
     ]
    }
   ],
   "source": [
    "# headers={'User-Agent': 'New '}\n",
    "r = requests.get('http://178.62.90.232/')\n",
    "\n",
    "# to see the information being passed in the header of the request\n",
    "print(r.request.headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accept-Encoding': 'gzip, deflate', 'Connection': 'keep-alive', 'User-Agent': 'New', 'Accept': '*/*'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get('http://178.62.90.232/', headers={'User-Agent':'New'})\n",
    "r.request.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robots.txt\n",
    "\n",
    "To check whether you are allowed to access Web pages using a scraper, make sure you check **`robots.txt`**.  Python has a class called [`RobotFileParser`](https://docs.python.org/3.0/library/urllib.robotparser.html) which does exactly this.  It is quite simple to use, and lets you know whether you can read the page.\n",
    "\n",
    "Look at the documentation and check whether you can read different parts of the [BBC](http://www.bbc.co.uk) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You don't need to write anything here\n",
    "from urllib.robotparser import RobotFileParser\n",
    "rp = RobotFileParser()\n",
    "rp.set_url('http://bbc.co.uk/robots.txt')\n",
    "rp.read()\n",
    "rp.can_fetch(\"*\", 'http://bbc.co.uk/news')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing HTML\n",
    "\n",
    "To parse the HTML, we will use the [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library.  This uses a class **`BeautifulSoup`** which accepts a **string** as a parameter (the HTML) and allows us to search through it - in other words Beautiful Soup is a Python library for pulling data out of HTML and XML files.  You can look through the documentation at the link for more of the details, but the basic important parts of it can be seen in the next cell:\n",
    "\n",
    "N.B. This uses version 4 of Beautiful Soup.  The previous version did not require you to specify a parser as one of the parameters, whereas this version does.  *For HTML you should use 'lxml', and for XML you should use 'xml'*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n",
      "<tr>\n",
      "<th>Table heading cell<br/></th><th>Another heading</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>Normal table cell and <br/></td>\n",
      "<td>This cell has a link going <a href=\"#\">Somewhere</a></td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "Table heading cellAnother heading\n",
      "\n",
      "\n",
      "Normal table cell and \n",
      "This cell has a link going Somewhere\n",
      "\n",
      "\n",
      "Table 2A second heading\n",
      "\n",
      "\n",
      "Cool content and \n",
      "This cell has a link going SomewhereElse\n",
      "\n",
      "link texts Somewhere\n",
      "link texts SomewhereElse\n",
      "\n",
      "\n",
      "<table>\n",
      "<tr>\n",
      "<th>Table 2<br/></th><th>A second heading</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>Cool content and <br/></td>\n",
      "<td>This cell has a link going <a href=\"#\">SomewhereElse</a></td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "\n",
      "\n",
      "An unordered (numbered) list item\n",
      "And another unordered list item\n",
      "\n",
      "\n",
      "This list item is ordered\n",
      "So is this one\n",
      "\n",
      "\n",
      "this is some text between tds\n",
      "\n",
      "column text Normal table cell and \n",
      "\n",
      "column text This cell has a link going Somewhere\n",
      "\n",
      "column text Cool content and \n",
      "\n",
      "column text This cell has a link going SomewhereElse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N.B. Make sure you have run the code in the first code cell with the HTML in it before doing this next bit.  \n",
    "# The code here relies on the `html` variable.\n",
    "\n",
    "# You don't need to write anything here\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Generate the BeautifulSoup instance, and make use of the LXML parser\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "# Find the first instance of the <table> element\n",
    "table = soup.find('table')\n",
    "print(table)\n",
    "\n",
    "\n",
    "# Find all instances of <tr> within the <table> element we just found\n",
    "# We could do that from any point in the HTML tree.\n",
    "rows = soup.find_all('tr')\n",
    "for r in rows:\n",
    "    print(r.text)\n",
    "\n",
    "links = soup.find_all('a')\n",
    "for l in links:\n",
    "    print('link texts', l.text)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# Find a table in the element with ID another_div\n",
    "table = soup.find(id='another_div').find('table')\n",
    "print(table)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "lists = soup.find_all('ul')\n",
    "for lis in lists:\n",
    "    print(lis.text)\n",
    "\n",
    "\n",
    "\n",
    "lister = soup.find_all('ol')\n",
    "for lisp in lister:\n",
    "    print(lisp.text)\n",
    "    \n",
    "print('\\nthis is some text between tds')\n",
    "cols = soup.find_all('td')\n",
    "for c in cols:\n",
    "    print('\\ncolumn text', c.text)\n",
    "\n",
    "\n",
    "# Get the value of an attribute\n",
    "soup.find('meta')['charset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the `.find()` method will give a `Tag` object, with all the properties of a HTML tag which can be explored, and the `find_all()` method will give a list of `Tag` objects (if they exist).\n",
    "\n",
    "Get some HTML from a page, and experiment using this library.  Aim to find the following:\n",
    "- All anchor (i.e., `<a>`) tags\n",
    "- The names of the id and class of the `<div>` tags\n",
    "- The text within some `<td>` tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"#\">Somewhere</a>, <a href=\"#\">SomewhereElse</a>]\n",
      "main\n",
      "['classy']\n",
      "another_div\n",
      "['classy']\n",
      "Normal table cell and \n",
      "This cell has a link going Somewhere\n",
      "Cool content and \n",
      "This cell has a link going SomewhereElse\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all('a'))\n",
    "for d in soup.find_all('div'):\n",
    "    print(d['id'])\n",
    "    print(d.attrs['class'])\n",
    "for t in soup.find_all('td'):\n",
    "    print(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
